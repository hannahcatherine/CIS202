{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hannahcatherine/CIS202/blob/main/Copy_of_(3)_Handwritten_Digit_Classification_Activity.ipynb%20\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Handwritten Digit Classification Activity\n",
        "\n",
        "In this activity we will build a machine learning model, speficially a decision tree classifier, that will detect the value of hand written digits. We will use the MNIST handwritten digit dataset, a common dataset used for instructional purposes.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "iRb5IiMkXtiy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Import Necessary Libraries\n",
        "In order to get the necessary code we need to build our decision tree classifier, we must import some libraries. For this activity, numpy, tensorflow, matplotlib and Scikit learn are used. To import the necessary libraries, follow the comments and fill in the code below. After you complete your code, run it by pressing the play button on the left side of the code block.\n",
        "\n",
        "After you complete your code, run it by pressing the play button on the left side of the code block. If you get stuck, please raise your hand or glance at the solutions section at the very bottom of this document."
      ],
      "metadata": {
        "id": "SrrCgwXnYhdg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "_ywssVOdoyyN"
      },
      "outputs": [],
      "source": [
        "# Some of this code is missing, add the necessary lines to import numpy\n",
        "# and tensorflow using the 'import' keyword. Use 'np' as the nickname for\n",
        "# numpy and 'tf' as the nickname for tensorflow. Remember that the 'as'\n",
        "# keyword is used to add nicknames\n",
        "# YOUR CODE GOES HERE ---\n",
        "\n",
        "# ---\n",
        "import numpy as np\n",
        "\n",
        "# Import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Import the MNIST dataset\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Below, we have imported the necessary function for constructing a\n",
        "# decision tree classifier, though we are missing the function to evaulate\n",
        "# the accuracy of our model. Import 'accuracy_score' from the 'sklearn.metrics'\n",
        "# module.\n",
        "## from sklearn.tree import DecisionTreeClassifier\n",
        "# YOUR CODE GOES HERE ---\n",
        "\n",
        "# ---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Load the Dataset\n",
        "The dataset we will be using is called the MNIST Handwritten Digit dataset. It consists of 28x28 pixel images that contain handwritten digits 0-9. We must load this dataset from one of our libraries in order to use it. To do so, call the library function `load_data()` from the `mnist` module. This function outputs the images and the labels from the dataset. It also already splits the dataset into a training set and a testing set for us. After loading the dataset the following variables will be defined:\n",
        "\n",
        "- `train_images` contains the images of the training set\n",
        "- `train_labels` contains the labels corresponding to the training images\n",
        "- `test_images` contains the images of the testing set\n",
        "- `test_labels` contains the labels corresponding to the testing images\n",
        "\n",
        "After you complete your code, run it by pressing the play button on the left side of the code block. If you get stuck, please raise your hand or glance at the solutions section at the very bottom of this document."
      ],
      "metadata": {
        "id": "XaLyNI32araf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0"
      ],
      "metadata": {
        "id": "B4r77VbHpaia"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dtc = models.Sequential()\n",
        "dtc.add(layers.MaxPooling2D((2, 2)))\n",
        "dtc.add(layers.MaxPooling2D((2, 2)))"
      ],
      "metadata": {
        "id": "mMpkzO7eCPhc"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Training the Decision Tree Classifier\n",
        "We are finally ready to train our decision tree classifier. In Scikit Learn, the library our decision tree classifier is from, the train function is called `fit`. It is named fit because when you call it you are 'fitting' the model to your data. Remember that training requires the images and the labels. (because how would our model know how to get better if it didn't have the labels?) As such, the `fit` function takes two inputs, the images and the labels. To train the model, call the `fit` function with the **transformed training images** and the **training labels**.\n",
        "\n",
        "After you complete your code, run it by pressing the play button on the left side of the code block. Note that this code block may take a little longer to run than others. If you get stuck, please raise your hand or glance at the solutions section at the very bottom of this document."
      ],
      "metadata": {
        "id": "6lqpjGMmjvRb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This function trains, or 'fits' the model to our data. Fill in the requried\n",
        "# inputs.\n",
        "##dtc.fit(train_images_transformed, train_labels)\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_images, train_labels, epochs=10,\n",
        "                    validation_data=(test_images, test_labels))\n"
      ],
      "metadata": {
        "id": "HKo8UQhBj1Sm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ef9f10fa-81f0-4b3f-ec71-bdd52895abec"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "Graph execution error:\n\nDetected at node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-45-90d3cff02e45>\", line 8, in <cell line: 8>\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1807, in fit\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1151, in train_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1209, in compute_loss\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 143, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 270, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 2454, in sparse_categorical_crossentropy\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend.py\", line 5775, in sparse_categorical_crossentropy\n\nlogits and labels must have the same first dimension, got logits shape [512,64] and labels shape [32]\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_train_function_3178]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-90d3cff02e45>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m               metrics=['accuracy'])\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m history = model.fit(train_images, train_labels, epochs=10, \n\u001b[0m\u001b[1;32m      9\u001b[0m                     validation_data=(test_images, test_labels))\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-45-90d3cff02e45>\", line 8, in <cell line: 8>\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1807, in fit\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1151, in train_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1209, in compute_loss\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 143, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 270, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 2454, in sparse_categorical_crossentropy\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend.py\", line 5775, in sparse_categorical_crossentropy\n\nlogits and labels must have the same first dimension, got logits shape [512,64] and labels shape [32]\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_train_function_3178]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Testing the Decision Tree Classifier\n",
        "Since our model has been hard at work training on our data, it is finally time to test its performance! We can do so by **predicting** the labels of images that the model has never seen before. We will do so by calling the `predict` function from our model (`dtc`) with the input being the **transformed testing images**.\n",
        "\n",
        "After you complete your code, run it by pressing the play button on the left side of the code block. Note that this code block may take a little longer to run than others. If you get stuck, please raise your hand or glance at the solutions section at the very bottom of this document."
      ],
      "metadata": {
        "id": "YzE8XRntlagh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This function gets the labels that the model predicts when given input images.\n",
        "# We want to get the predicted labels for our training data. To do so, fill in\n",
        "# the required input.\n",
        "predicted_labels = dtc.predict() # THIS LINE IS INCOMPLETE"
      ],
      "metadata": {
        "id": "e8WzlAHwCZSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Evaluating Performance\n",
        "Now it is time to see how our model performed on the testing data. To do so we will use the `accuracy_score` function that we imported earlier. This function takes two inputs, the **predicted labels** and the **actual labels**. Note that the actual labels are the test labels from the dataset, a.k.a `test_labels`. This code will show the accuracy of the model as a percentage that it got correct (much like a test). Did your model pass?\n",
        "\n",
        "After you complete your code, run it by pressing the play button on the left side of the code block. Note that this code block may take a little longer to run than others. If you get stuck, please raise your hand or glance at the solutions section at the very bottom of this document"
      ],
      "metadata": {
        "id": "MC-5omu9mwel"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill in the required inputs. Remember that the accuracy score function takes\n",
        "# the predicted labels and the actual labels.\n",
        "accuracy = accuracy_score() # THIS LINE IS INCOMPLETE\n",
        "print(accuracy * 100)"
      ],
      "metadata": {
        "id": "0_-Kh1-dENCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Visualizing Performance\n",
        "Finally, we will view a sample of the test set along with the predictions our model made. The label is green if the model got it correct and red if it got it incorrect. Closely observe the images that the model falsely predicted. Are these predictions reasonable? Based on these findings, what does the model struggle with?\n",
        "\n",
        "This section has been completed for you. Run the code below using the run button."
      ],
      "metadata": {
        "id": "rFMmRBr_n94U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_predictions(width, height):\n",
        "  plt.figure(figsize = (2*width, 2*height))\n",
        "  for i in range(width*height):\n",
        "    predicted_label = tf.argmax(predicted_labels[i])\n",
        "    actual_label = tf.argmax(test_labels[i])\n",
        "    if predicted_label == actual_label:\n",
        "      color = \"green\"\n",
        "    else:\n",
        "      color = \"red\"\n",
        "\n",
        "    plt.subplot(width, height, i + 1)\n",
        "    plt.grid(False)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.imshow(test_images[i], cmap = \"gray\")\n",
        "\n",
        "    plt.xlabel(\"pred: {}, actual: {}\".format(predicted_label, actual_label), color = color)\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "\n",
        "visualize_predictions(5, 5)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "N62sZ-xoEZ-p"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}